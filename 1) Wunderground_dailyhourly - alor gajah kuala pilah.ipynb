{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Weather Station for Wunderground\n",
    "\n",
    "**Kuala Pilah & Alor Gajah** \n",
    "Location: MALACCA AIRPORT STATION https://www.wunderground.com/history/daily/my/malacca/WMKM/date/\n",
    "\n",
    "\n",
    "**Jengka & Gambang** \n",
    "Location: KUANTAN AIRPORT STATION https://www.wunderground.com/history/daily/my/kuantan/WMKD/date/ \n",
    "\n",
    "\n",
    "**Permatang Pauh**\n",
    "Location: PENANG INTERNATIONAL AIRPORT STATION https://www.wunderground.com/history/daily/my/bayan-lepas/WMKP/date/\n",
    "\n",
    "**Segamat**\n",
    "Location: SEGAMAT AIRPORT STATION https://www.wunderground.com/history/daily/my/segamat/WMAZ/date/\n",
    "\n",
    "**Dungun**\n",
    "  Location: KERTEH AIRPORT STATION https://www.wunderground.com/history/daily/my/kerteh/WMKE/date/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def render_page(url,type):\n",
    "        options=webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        if type ==\"C\":\n",
    "            element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, 'wuSettings'))\n",
    "            )\n",
    "            element.click()\n",
    "            element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"wuSettings-quick\"]/div/a[2]')))\n",
    "            element.click()\n",
    "            time.sleep(3)\n",
    "            r = driver.page_source\n",
    "            driver.quit()\n",
    "        if type==\"F\":\n",
    "            r = driver.page_source\n",
    "            driver.quit()\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_scraper(page, dates, type):\n",
    "    all_data = []  # List to store each day's DataFrame\n",
    "\n",
    "    for d in dates:\n",
    "        url = f\"{page}{d}\"\n",
    "        r = render_page(url, type)\n",
    "        soup = BS(r, \"html.parser\")\n",
    "        container = soup.find('lib-city-history-observation')\n",
    "        check = container.find('tbody')\n",
    "\n",
    "        data = []\n",
    "        data_hour = []\n",
    "        for i in check.find_all('span', class_='ng-star-inserted'):\n",
    "            trial = i.get_text()\n",
    "            data_hour.append(trial)\n",
    "\n",
    "        for i in check.find_all('span', class_='wu-value wu-value-to'):\n",
    "            trial = i.get_text()\n",
    "            data.append(trial)\n",
    "\n",
    "        numbers = pd.DataFrame([data[i:i+7] for i in range(0, len(data), 7)], columns=[\"Temperature\", \"Dew Point\", \"Humidity\", \"Wind Speed\", \"Wind Gust\", \"Pressure\", \"Precipitation\"])\n",
    "        hour = pd.DataFrame(data_hour[0::17], columns=[\"Time\"])\n",
    "        wind = pd.DataFrame(data_hour[7::17], columns=[\"Wind\"])\n",
    "        condition = pd.DataFrame(data_hour[16::17], columns=[\"Condition\"])\n",
    "\n",
    "        dfs = [hour, numbers, wind, condition]\n",
    "\n",
    "        df_final = reduce(lambda left, right: pd.merge(left, right, left_index=True, right_index=True), dfs)\n",
    "        df_final['Date'] = d\n",
    "\n",
    "        all_data.append(df_final)  # Append each day's DataFrame to the list\n",
    "\n",
    "        print(f\"{d} finished!\")\n",
    "\n",
    "    output = pd.concat(all_data, ignore_index=True)  # Concatenate all DataFrames into a single DataFrame\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Please change the base_url according to the Wunderground location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 finished!\n",
      "2024-07-02 finished!\n",
      "2024-07-03 finished!\n",
      "2024-07-04 finished!\n",
      "2024-07-05 finished!\n",
      "2024-07-06 finished!\n",
      "2024-07-07 finished!\n",
      "2024-07-08 finished!\n",
      "2024-07-09 finished!\n",
      "2024-07-10 finished!\n",
      "2024-07-11 finished!\n",
      "2024-07-12 finished!\n",
      "2024-07-13 finished!\n",
      "2024-07-14 finished!\n",
      "2024-07-15 finished!\n",
      "2024-07-16 finished!\n",
      "2024-07-17 finished!\n",
      "2024-07-18 finished!\n",
      "2024-07-19 finished!\n",
      "2024-07-20 finished!\n",
      "2024-07-21 finished!\n",
      "2024-07-22 finished!\n",
      "2024-07-23 finished!\n",
      "2024-07-24 finished!\n",
      "2024-07-25 finished!\n",
      "2024-07-26 finished!\n",
      "2024-07-27 finished!\n",
      "2024-07-28 finished!\n",
      "2024-07-29 finished!\n",
      "2024-07-30 finished!\n",
      "2024-07-31 finished!\n"
     ]
    }
   ],
   "source": [
    "## -- 2/7/2024 4:01 pm\n",
    "# Define the base URL and start date\n",
    "base_url = \"https://www.wunderground.com/history/daily/my/malacca/WMKM/date/\"\n",
    "start_date = datetime(2024, 7, 1)\n",
    "\n",
    "# Define the number of days to iterate through\n",
    "num_days = 31\n",
    "all_data = pd.DataFrame()  # Initialize an empty DataFrame to concatenate results\n",
    "\n",
    "# Loop through the dates and call the hourly_scraper function\n",
    "for i in range(num_days):\n",
    "    current_date = start_date + timedelta(days=i)\n",
    "    formatted_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Call the hourly_scraper function for the current date\n",
    "    hourly1 = hourly_scraper(base_url, [formatted_date], \"F\")\n",
    "\n",
    "    # Concatenate the result to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, hourly1], ignore_index=True)\n",
    "\n",
    "    # Optionally, add a delay to avoid overloading the website\n",
    "    import time\n",
    "    time.sleep(10)  # Sleep for 5 seconds between requests (adjust as needed)\n",
    "\n",
    "# Save all data to a single CSV file if needed\n",
    "all_data.to_csv('July_2024_KP.csv', index=False)\n",
    "\n",
    "\n",
    "import winsound\n",
    "\n",
    "# Your long-running code here\n",
    "\n",
    "# Play a sound when done\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('Jan_17July_2024_KP.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
